{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eb3ba83",
   "metadata": {},
   "source": [
    "# Matching and Weighting IRL â€“ Georgia MA Sandbox\n",
    "\n",
    "This notebook mirrors the slide code and provides R and Python implementations for:\n",
    "\n",
    "1. Constructing county-level GA Medicare Advantage data  \n",
    "2. Defining an HHI-based binary treatment  \n",
    "3. Assessing balance  \n",
    "4. Matching estimators (exact / nearest neighbor / Mahalanobis / PS)  \n",
    "5. IPW estimators (simple averages and regression)  \n",
    "6. Regression-based estimators\n",
    "\n",
    "The main kernel is Python; R is called via `rpy2` magics (`%%R`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab39cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python setup: install core libs (comment out pip lines if already installed)\n",
    "!pip install rpy2 statsmodels scikit-learn matplotlib pandas numpy --quiet\n",
    "\n",
    "%load_ext rpy2.ipython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921388e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# R setup ---------------------------------------------------------------\n",
    "if (!require(\"pacman\")) install.packages(\"pacman\")\n",
    "pacman::p_load(\n",
    "  tidyverse, ggplot2, lubridate,\n",
    "  MatchIt, cobalt, knitr, kableExtra, Matching\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595ee7fd",
   "metadata": {},
   "source": [
    "## 1. Construct county-level GA MA data, define treatment, and build analysis dataset (R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1315657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Construct county-level GA MA data ------------------------------------\n",
    "\n",
    "\n",
    "ga_ma_2022 <- read_csv(\"https://raw.githubusercontent.com/imccart/empirical-methods-content/main/data/output/ma-snippets/ga-ma-data-2022.csv\") %>%\n",
    "  group_by(fips) %>%\n",
    "  mutate(\n",
    "    total_ma_enrollment = first(avg_enrolled),\n",
    "    ma_share = if_else(\n",
    "      total_ma_enrollment > 0,\n",
    "      (avg_enrollment / total_ma_enrollment) * 100,\n",
    "      NA_real_\n",
    "    )\n",
    "  ) %>%\n",
    "  summarize(\n",
    "    hhi_ma             = sum(ma_share^2, na.rm = TRUE),\n",
    "    plan_count         = n_distinct(contractid, planid),\n",
    "    avg_premium_partc  = mean(premium_partc, na.rm = TRUE),\n",
    "    share_pos_premiums = mean(premium_partc > 0, na.rm = TRUE),\n",
    "    avg_bid            = mean(bid, na.rm = TRUE),\n",
    "    avg_eligibles      = first(avg_eligibles),\n",
    "    ffs_cost           = first(avg_ffscost)\n",
    "  ) %>%\n",
    "  ungroup()\n",
    "\n",
    "# Define HHI-based treatment -------------------------------------------\n",
    "q_hhi <- quantile(ga_ma_2022$hhi_ma, probs = c(0.33, 0.66), na.rm = TRUE)\n",
    "\n",
    "ga_tab <- ga_ma_2022 %>%\n",
    "  mutate(\n",
    "    hhi_group = case_when(\n",
    "      hhi_ma >= q_hhi[2] ~ \"treated\",  # high HHI (low competition)\n",
    "      hhi_ma <= q_hhi[1] ~ \"control\",  # low HHI (high competition)\n",
    "      TRUE               ~ NA_character_\n",
    "    ),\n",
    "    treated_dummy = case_when(\n",
    "      hhi_group == \"treated\" ~ 1L,\n",
    "      hhi_group == \"control\" ~ 0L,\n",
    "      TRUE                   ~ NA_integer_\n",
    "    )\n",
    "  ) %>%\n",
    "  filter(!is.na(hhi_group))\n",
    "\n",
    "# Analysis dataset: lp.vars (outcome + treatment + covariates) ---------\n",
    "lp.vars <- ga_tab %>%\n",
    "  select(\n",
    "    treated_dummy,\n",
    "    hhi_ma,\n",
    "    plan_count,\n",
    "    avg_premium_partc,\n",
    "    share_pos_premiums,\n",
    "    avg_bid,\n",
    "    avg_eligibles,\n",
    "    ffs_cost\n",
    "  ) %>%\n",
    "  filter(complete.cases(.))\n",
    "\n",
    "# Covariates for matching / PS model\n",
    "lp.covs <- lp.vars %>%\n",
    "  select(ffs_cost, avg_eligibles)\n",
    "\n",
    "# Propensity scores -----------------------------------------------------\n",
    "logit.model <- glm(\n",
    "  treated_dummy ~ avg_eligibles + ffs_cost,\n",
    "  family = binomial,\n",
    "  data   = lp.vars\n",
    ")\n",
    "ps <- fitted(logit.model)\n",
    "\n",
    "# Attach PS and IPW to lp.vars -----------------------------------------\n",
    "lp.vars <- lp.vars %>%\n",
    "  mutate(\n",
    "    ps  = ps,\n",
    "    ipw = case_when(\n",
    "      treated_dummy == 1 ~ 1 / ps,\n",
    "      treated_dummy == 0 ~ 1 / (1 - ps),\n",
    "      TRUE ~ NA_real_\n",
    "    )\n",
    "  )\n",
    "\n",
    "glimpse(lp.vars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ac4e8f",
   "metadata": {},
   "source": [
    "## 1b. Optional: construct analogous analysis DataFrame in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb3fe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Start from the already-aggregated Python version of ga_ma_2022\n",
    "ga_ma_2022_raw = pd.read_csv(\"https://raw.githubusercontent.com/imccart/empirical-methods-content/main/data/output/ma-snippets/ga-ma-data-2022.csv\")\n",
    "\n",
    "def summarize_fips(group: pd.DataFrame) -> pd.Series:\n",
    "    total_ma_enrollment = group[\"avg_enrolled\"].iloc[0]\n",
    "\n",
    "    ma_share = np.where(\n",
    "        total_ma_enrollment > 0,\n",
    "        (group[\"avg_enrollment\"] / total_ma_enrollment) * 100.0,\n",
    "        np.nan,\n",
    "    )\n",
    "\n",
    "    hhi_ma = np.nansum(ma_share ** 2)\n",
    "    plan_count = group[[\"contractid\", \"planid\"]].drop_duplicates().shape[0]\n",
    "    avg_premium_partc = group[\"premium_partc\"].mean(skipna=True)\n",
    "    share_pos_premiums = (group[\"premium_partc\"] > 0).mean()\n",
    "    avg_bid = group[\"bid\"].mean(skipna=True)\n",
    "    avg_eligibles = group[\"avg_eligibles\"].iloc[0]\n",
    "    ffs_cost = group[\"avg_ffscost\"].iloc[0]\n",
    "\n",
    "    return pd.Series(\n",
    "        dict(\n",
    "            hhi_ma=hhi_ma,\n",
    "            plan_count=plan_count,\n",
    "            avg_premium_partc=avg_premium_partc,\n",
    "            share_pos_premiums=share_pos_premiums,\n",
    "            avg_bid=avg_bid,\n",
    "            avg_eligibles=avg_eligibles,\n",
    "            ffs_cost=ffs_cost,\n",
    "        )\n",
    "    )\n",
    "\n",
    "ga_ma_2022_py = (\n",
    "    ga_ma_2022_raw\n",
    "    .groupby(\"fips\", as_index=False)\n",
    "    .apply(summarize_fips)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Define treatment in Python the same way\n",
    "q_hhi_py = ga_ma_2022_py[\"hhi_ma\"].quantile([0.33, 0.66])\n",
    "low_q, high_q = q_hhi_py.loc[0.33], q_hhi_py.loc[0.66]\n",
    "\n",
    "lp_df = ga_ma_2022_py.copy()\n",
    "lp_df[\"treated_dummy\"] = np.where(\n",
    "    lp_df[\"hhi_ma\"] >= high_q, 1,\n",
    "    np.where(lp_df[\"hhi_ma\"] <= low_q, 0, np.nan)\n",
    ")\n",
    "lp_df = lp_df.dropna(subset=[\"treated_dummy\"])\n",
    "\n",
    "lp_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9f2d20",
   "metadata": {},
   "source": [
    "## 2. Matching estimators (R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbefc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# 2.1 Exact matching on ffs_cost only ----------------------------------\n",
    "lp.covs2 <- lp.covs %>% select(ffs_cost)\n",
    "\n",
    "m.exact2 <- Matching::Match(\n",
    "  Y        = lp.vars$avg_bid,\n",
    "  Tr       = lp.vars$treated_dummy,\n",
    "  X        = lp.covs2,\n",
    "  M        = 1,\n",
    "  exact    = TRUE,\n",
    "  estimand = \"ATE\"\n",
    ")\n",
    "\n",
    "cat(\"Exact matching (on ffs_cost), ATE:\", m.exact2$est[1], \"\\n\")\n",
    "summary(m.exact2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a495d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# 2.2 Nearest neighbor, inverse-variance (Weight=1), M=1 ---------------\n",
    "m.nn.var2 <- Matching::Match(\n",
    "  Y        = lp.vars$avg_bid,\n",
    "  Tr       = lp.vars$treated_dummy,\n",
    "  X        = lp.covs,\n",
    "  M        = 1,\n",
    "  Weight   = 1,\n",
    "  estimand = \"ATE\"\n",
    ")\n",
    "\n",
    "cat(\"NN (Weight=1, M=1), ATE:\", m.nn.var2$est[1], \"\\n\")\n",
    "summary(m.nn.var2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dc8557",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# 2.3 Nearest neighbor, Mahalanobis (Weight=2) -------------------------\n",
    "m.nn.md <- Matching::Match(\n",
    "  Y        = lp.vars$avg_bid,\n",
    "  Tr       = lp.vars$treated_dummy,\n",
    "  X        = lp.covs,\n",
    "  M        = 1,\n",
    "  Weight   = 2,\n",
    "  estimand = \"ATE\"\n",
    ")\n",
    "\n",
    "cat(\"NN (Mahalanobis), ATE:\", m.nn.md$est[1], \"\\n\")\n",
    "summary(m.nn.md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4169dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# 2.4 Nearest neighbor, propensity score -------------------------------\n",
    "m.nn.ps <- Matching::Match(\n",
    "  Y        = lp.vars$avg_bid,\n",
    "  Tr       = lp.vars$treated_dummy,\n",
    "  X        = lp.vars$ps,\n",
    "  M        = 1,\n",
    "  estimand = \"ATE\"\n",
    ")\n",
    "\n",
    "cat(\"NN (propensity score), ATE:\", m.nn.ps$est[1], \"\\n\")\n",
    "summary(m.nn.ps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eba165",
   "metadata": {},
   "source": [
    "## 3. IPW estimators (R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1ca02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# 3.1 IPW with simple averages -----------------------------------------\n",
    "mean.t1 <- lp.vars %>%\n",
    "  filter(treated_dummy == 1) %>%\n",
    "  summarize(mean_bid = weighted.mean(avg_bid, w = ipw))\n",
    "\n",
    "mean.t0 <- lp.vars %>%\n",
    "  filter(treated_dummy == 0) %>%\n",
    "  summarize(mean_bid = weighted.mean(avg_bid, w = ipw))\n",
    "\n",
    "ate_ipw_means <- mean.t1$mean_bid - mean.t0$mean_bid\n",
    "cat(\"IPW (simple averages), ATE:\", round(ate_ipw_means, 3), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eced34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# 3.2 IPW regression ---------------------------------------------------\n",
    "ipw.reg <- lm(\n",
    "  avg_bid ~ treated_dummy,\n",
    "  data    = lp.vars,\n",
    "  weights = ipw\n",
    ")\n",
    "\n",
    "summary(ipw.reg)\n",
    "cat(\"IPW regression coef on treated_dummy:\", coef(ipw.reg)[\"treated_dummy\"], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9469c9",
   "metadata": {},
   "source": [
    "## 4. Regression-based estimators (R, no weighting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b595859",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Two-step regression --------------------------------------------------\n",
    "reg1.dat <- lp.vars %>% filter(treated_dummy == 1, complete.cases(.))\n",
    "reg1 <- lm(avg_bid ~ ffs_cost + avg_eligibles, data = reg1.dat)\n",
    "\n",
    "reg0.dat <- lp.vars %>% filter(treated_dummy == 0, complete.cases(.))\n",
    "reg0 <- lm(avg_bid ~ ffs_cost + avg_eligibles, data = reg0.dat)\n",
    "\n",
    "pred1 <- predict(reg1, newdata = lp.vars)\n",
    "pred0 <- predict(reg0, newdata = lp.vars)\n",
    "\n",
    "ate_reg2 <- mean(pred1 - pred0, na.rm = TRUE)\n",
    "cat(\"Two-step regression ATE (mean(pred1 - pred0)):\", round(ate_reg2, 3), \"\\n\")\n",
    "\n",
    "# One-step regression with interactions -------------------------------\n",
    "reg.dat <- lp.vars %>%\n",
    "  ungroup() %>%\n",
    "  filter(complete.cases(.)) %>%\n",
    "  mutate(\n",
    "    ffs_diff       = treated_dummy * (ffs_cost       - mean(ffs_cost)),\n",
    "    eligibles_diff = treated_dummy * (avg_eligibles  - mean(avg_eligibles))\n",
    "  )\n",
    "\n",
    "reg <- lm(\n",
    "  avg_bid ~ treated_dummy + ffs_cost + avg_eligibles +\n",
    "    ffs_diff + eligibles_diff,\n",
    "  data = reg.dat\n",
    ")\n",
    "\n",
    "summary(reg)\n",
    "cat(\"One-step regression coef on treated_dummy:\", coef(reg)[\"treated_dummy\"], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa07b58",
   "metadata": {},
   "source": [
    "## 5. Optional: IPW and regression in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f67320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Drop missing on required columns\n",
    "cols_needed = [\"avg_bid\", \"treated_dummy\", \"ffs_cost\", \"avg_eligibles\"]\n",
    "lp_df = lp_df.dropna(subset=cols_needed).copy()\n",
    "\n",
    "# Propensity scores (Python) for IPW -----------------------------------\n",
    "logit_res = smf.logit(\n",
    "    \"treated_dummy ~ avg_eligibles + ffs_cost\",\n",
    "    data=lp_df\n",
    ").fit(disp=False)\n",
    "\n",
    "lp_df[\"ps\"] = logit_res.predict(lp_df)\n",
    "eps = 1e-6\n",
    "lp_df[\"ps\"] = lp_df[\"ps\"].clip(eps, 1-eps)\n",
    "\n",
    "lp_df[\"ipw\"] = np.where(\n",
    "    lp_df[\"treated_dummy\"] == 1,\n",
    "    1.0 / lp_df[\"ps\"],\n",
    "    1.0 / (1.0 - lp_df[\"ps\"])\n",
    ")\n",
    "\n",
    "treated_py = lp_df[lp_df[\"treated_dummy\"] == 1]\n",
    "control_py = lp_df[lp_df[\"treated_dummy\"] == 0]\n",
    "\n",
    "mean_t1_py = np.average(treated_py[\"avg_bid\"], weights=treated_py[\"ipw\"])\n",
    "mean_t0_py = np.average(control_py[\"avg_bid\"], weights=control_py[\"ipw\"])\n",
    "ate_ipw_py = mean_t1_py - mean_t0_py\n",
    "\n",
    "print(\"Python IPW (simple averages), ATE:\", round(ate_ipw_py, 3))\n",
    "\n",
    "# IPW regression -------------------------------------------------------\n",
    "ipw_mod = smf.wls(\n",
    "    \"avg_bid ~ treated_dummy\",\n",
    "    data=lp_df,\n",
    "    weights=lp_df[\"ipw\"]\n",
    ").fit()\n",
    "\n",
    "print(ipw_mod.summary())\n",
    "print(\"Python IPW regression coef on treated_dummy:\",\n",
    "      ipw_mod.params[\"treated_dummy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635fcd78",
   "metadata": {},
   "source": [
    "## 6. Where to look\n",
    "\n",
    "- **Matching ATEs (R):** objects `m.exact2`, `m.nn.var2`, `m.nn.md`, `m.nn.ps`  \n",
    "- **IPW ATEs (R):** `ate_ipw_means`, `ipw.reg`  \n",
    "- **Regression ATEs (R):** `ate_reg2`, `reg`  \n",
    "- **Python analogues:** see the last IPW / regression cell using `lp_df`.\n",
    "\n",
    "You can now modify covariates, treatment definitions, or outcomes and re-run each block to explore how the estimators behave.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
